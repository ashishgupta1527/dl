{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UbWTdId4mj6p",
        "outputId": "03824c35-3227-4aab-eb6d-a06e292fbbe5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "12/12 [==============================] - 4s 29ms/step - loss: 16.2622 - accuracy: 0.5385 - val_loss: 0.9770 - val_accuracy: 0.8901\n",
            "Epoch 2/50\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 2.5896 - accuracy: 0.6923 - val_loss: 0.8517 - val_accuracy: 0.8132\n",
            "Epoch 3/50\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1.3846 - accuracy: 0.8049 - val_loss: 1.1424 - val_accuracy: 0.8791\n",
            "Epoch 4/50\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.6369 - accuracy: 0.8956 - val_loss: 1.1299 - val_accuracy: 0.8791\n",
            "Epoch 5/50\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.5140 - accuracy: 0.9038 - val_loss: 0.7921 - val_accuracy: 0.8901\n",
            "Epoch 6/50\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4950 - accuracy: 0.8929 - val_loss: 0.8408 - val_accuracy: 0.8901\n",
            "Epoch 7/50\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.9304 - accuracy: 0.8434 - val_loss: 3.2599 - val_accuracy: 0.7692\n",
            "Epoch 8/50\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 1.4222 - accuracy: 0.8132 - val_loss: 3.7952 - val_accuracy: 0.7473\n",
            "Epoch 9/50\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 1.2832 - accuracy: 0.8159 - val_loss: 1.4974 - val_accuracy: 0.8571\n",
            "Epoch 10/50\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.5117 - accuracy: 0.9093 - val_loss: 0.9955 - val_accuracy: 0.8901\n",
            "Epoch 11/50\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.6028 - accuracy: 0.9066 - val_loss: 0.6098 - val_accuracy: 0.9121\n",
            "Epoch 12/50\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3926 - accuracy: 0.9011 - val_loss: 0.8173 - val_accuracy: 0.8901\n",
            "Epoch 13/50\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.6964 - accuracy: 0.8956 - val_loss: 0.6395 - val_accuracy: 0.9121\n",
            "Epoch 14/50\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4718 - accuracy: 0.9148 - val_loss: 0.7670 - val_accuracy: 0.8901\n",
            "Epoch 15/50\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.7210 - accuracy: 0.8846 - val_loss: 0.3794 - val_accuracy: 0.9121\n",
            "Epoch 16/50\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4241 - accuracy: 0.8984 - val_loss: 0.4807 - val_accuracy: 0.9011\n",
            "Epoch 17/50\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.5122 - accuracy: 0.8929 - val_loss: 0.3909 - val_accuracy: 0.9011\n",
            "Epoch 18/50\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4380 - accuracy: 0.9038 - val_loss: 1.4280 - val_accuracy: 0.8242\n",
            "Epoch 19/50\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.6757 - accuracy: 0.8874 - val_loss: 0.3290 - val_accuracy: 0.9121\n",
            "Epoch 20/50\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3808 - accuracy: 0.8984 - val_loss: 0.7124 - val_accuracy: 0.8132\n",
            "Epoch 21/50\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.5201 - accuracy: 0.8874 - val_loss: 0.5338 - val_accuracy: 0.9011\n",
            "Epoch 22/50\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4857 - accuracy: 0.8984 - val_loss: 1.6376 - val_accuracy: 0.8022\n",
            "Epoch 23/50\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.5450 - accuracy: 0.8984 - val_loss: 0.3034 - val_accuracy: 0.9011\n",
            "Epoch 24/50\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.5161 - accuracy: 0.9038 - val_loss: 0.4756 - val_accuracy: 0.9121\n",
            "Epoch 25/50\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.6197 - accuracy: 0.8846 - val_loss: 1.3049 - val_accuracy: 0.8242\n",
            "Epoch 26/50\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4830 - accuracy: 0.8984 - val_loss: 0.4000 - val_accuracy: 0.9231\n",
            "Epoch 27/50\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3267 - accuracy: 0.9093 - val_loss: 0.2826 - val_accuracy: 0.9011\n",
            "Epoch 28/50\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3509 - accuracy: 0.9148 - val_loss: 0.8277 - val_accuracy: 0.8352\n",
            "Epoch 29/50\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4476 - accuracy: 0.9093 - val_loss: 0.7528 - val_accuracy: 0.7692\n",
            "Epoch 30/50\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4036 - accuracy: 0.8929 - val_loss: 1.2886 - val_accuracy: 0.8132\n",
            "Epoch 31/50\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4617 - accuracy: 0.9011 - val_loss: 0.2709 - val_accuracy: 0.9011\n",
            "Epoch 32/50\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2875 - accuracy: 0.9258 - val_loss: 0.6254 - val_accuracy: 0.8132\n",
            "Epoch 33/50\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3208 - accuracy: 0.9121 - val_loss: 0.3292 - val_accuracy: 0.9121\n",
            "Epoch 34/50\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.2769 - accuracy: 0.9203 - val_loss: 0.2542 - val_accuracy: 0.9121\n",
            "Epoch 35/50\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.2448 - accuracy: 0.9258 - val_loss: 0.2211 - val_accuracy: 0.9011\n",
            "Epoch 36/50\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.2797 - accuracy: 0.9258 - val_loss: 0.2063 - val_accuracy: 0.9121\n",
            "Epoch 37/50\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.2606 - accuracy: 0.9286 - val_loss: 0.3133 - val_accuracy: 0.9121\n",
            "Epoch 38/50\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3848 - accuracy: 0.9093 - val_loss: 0.7570 - val_accuracy: 0.7473\n",
            "Epoch 39/50\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4347 - accuracy: 0.8901 - val_loss: 0.2226 - val_accuracy: 0.9011\n",
            "Epoch 40/50\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2651 - accuracy: 0.9203 - val_loss: 0.2065 - val_accuracy: 0.9121\n",
            "Epoch 41/50\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1879 - accuracy: 0.9451 - val_loss: 0.2990 - val_accuracy: 0.9121\n",
            "Epoch 42/50\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2829 - accuracy: 0.9231 - val_loss: 0.7210 - val_accuracy: 0.8352\n",
            "Epoch 43/50\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3575 - accuracy: 0.9011 - val_loss: 0.1900 - val_accuracy: 0.9121\n",
            "Epoch 44/50\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.7639 - accuracy: 0.8379 - val_loss: 1.0067 - val_accuracy: 0.7363\n",
            "Epoch 45/50\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4997 - accuracy: 0.8791 - val_loss: 0.6628 - val_accuracy: 0.8681\n",
            "Epoch 46/50\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3063 - accuracy: 0.9231 - val_loss: 0.2595 - val_accuracy: 0.9121\n",
            "Epoch 47/50\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.2683 - accuracy: 0.9341 - val_loss: 0.8016 - val_accuracy: 0.7582\n",
            "Epoch 48/50\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.6550 - accuracy: 0.8736 - val_loss: 1.5968 - val_accuracy: 0.7912\n",
            "Epoch 49/50\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.5464 - accuracy: 0.8901 - val_loss: 0.2543 - val_accuracy: 0.9231\n",
            "Epoch 50/50\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.5328 - accuracy: 0.8709 - val_loss: 0.4557 - val_accuracy: 0.8901\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.2952 - accuracy: 0.8860\n",
            "Test Loss: 0.2952, Test Accuracy: 0.8860\n"
          ]
        }
      ],
      "source": [
        "#Before Optimization\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "# Load the Breast Cancer dataset\n",
        "data = load_breast_cancer()\n",
        "X = data.data\n",
        "y = data.target\n",
        "# Convert labels to one-hot encoding\n",
        "y_one_hot = tf.keras.utils.to_categorical(y, num_classes=2)\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y_one_hot, test_size=0.2,\n",
        "random_state=42)\n",
        "# Build the neural network model\n",
        "model = keras.Sequential([\n",
        " layers.Input(shape=(30,)),\n",
        " layers.Dense(128, activation='relu'),\n",
        " layers.Dense(64, activation='relu'),\n",
        " layers.Dense(2, activation='softmax')\n",
        "])\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy',\n",
        "metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "batch_size = 32\n",
        "epochs = 50\n",
        "model.fit(X_train, y_train, batch_size=batch_size, epochs=epochs,\n",
        "validation_split=0.2)\n",
        "# Evaluate the model on the test data\n",
        "test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
        "print(f\"Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#After Optimization\n",
        "# Build the neural network model with regularization, dropout, and early stopping\n",
        "model = keras.Sequential([\n",
        " layers.Input(shape=(30,)),\n",
        " layers.Dense(128, activation='relu',\n",
        "kernel_regularizer=keras.regularizers.l2(0.01)),\n",
        " layers.Dropout(0.5), # Adding dropout with a rate of 0.5\n",
        " layers.Dense(64, activation='relu',\n",
        "kernel_regularizer=keras.regularizers.l2(0.01)),\n",
        " layers.Dropout(0.5), # Adding dropout with a rate of 0.5\n",
        " layers.Dense(2, activation='softmax')\n",
        "])\n",
        "\n"
      ],
      "metadata": {
        "id": "p-F-J6u1mq3F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy',\n",
        "metrics=['accuracy'])\n"
      ],
      "metadata": {
        "id": "gKCP5wmhn6pP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Implement early stopping\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=10,\n",
        "restore_best_weights=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 210
        },
        "id": "3fPhGP_aqJeF",
        "outputId": "36a0c4a1-10c1-4f8c-8492-78ab170237c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-c8d1e95f84f8>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Implement early stopping\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m early_stopping = EarlyStopping(monitor='val_loss', patience=10,\n\u001b[0m\u001b[1;32m      3\u001b[0m restore_best_weights=True)\n",
            "\u001b[0;31mNameError\u001b[0m: name 'EarlyStopping' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model with early stopping\n",
        "batch_size = 32\n",
        "epochs = 100\n",
        "model.fit(X_train, y_train, batch_size=batch_size, epochs=epochs,\n",
        "validation_split=0.2, callbacks=[early_stopping])"
      ],
      "metadata": {
        "id": "bQS36uJhqLbJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Xl0P4A9lqOns"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}